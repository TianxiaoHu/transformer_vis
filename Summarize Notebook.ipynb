{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook allows for generating articles and summaries, along with the gold summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rinokeras\n",
    "from rinokeras.models.transformer import Transformer\n",
    "import tensorflow.contrib.eager as tfe\n",
    "from Dataset import Dataset\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import os, time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the json below with the newest dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32003\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(\"nl_summaries_small_eval.0.4.json\")\n",
    "dataset.load()\n",
    "\n",
    "input_length = 400; output_length = 100; dim = 304\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "offset = 3 # Hack for now, due to beginning of word vocab\n",
    "padI = dataset.vocab.index('<PAD>')\n",
    "n_vocab = len(dataset.vocab)\n",
    "print(n_vocab)\n",
    "print(padI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eager mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(discrete=True, n_layers=3, n_symbols_in=n_vocab, d_model=dim, n_symbols_out=n_vocab, embedding_initializer=np.zeros((n_vocab, dim)), share_source_target_embedding=True)\n",
    "\n",
    "# Very hacky: do a forward run to force the model to be built, before loading the weights.\n",
    "encode, decode, mask, decode_mask = dataset.build_batch(['input', 'output', 'input_mask', 'output_mask'], size=64, cut='evaluation', types=[tf.int32,tf.int32,tf.bool,tf.bool])\n",
    "decoded_logits = model(encode, decode, encoder_mask=mask, decoder_mask=decode_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the weight file below with the latest weight file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"summarize_adam_ckpt.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 2.636415481567383\n"
     ]
    }
   ],
   "source": [
    "# Testing loss in eager mode\n",
    "\n",
    "encode, decode, mask, decode_mask = dataset.build_batch(['input', 'output', 'input_mask', 'output_mask'], size=64, cut='evaluation', types=[tf.int32,tf.int32,tf.bool,tf.bool])\n",
    "\n",
    "decoded_logits = model(encode, decode, encoder_mask=mask, decoder_mask=decode_mask)\n",
    "test_loss = tf.losses.sparse_softmax_cross_entropy(decode, decoded_logits, tf.cast(decode_mask, tf.float32))\n",
    "\n",
    "# test_loss = tf.contrib.seq2seq.sequence_loss(decoded_logits, decode, tf.cast(decode_mask, tf.float32))\n",
    "print(\"Eval loss:\",float(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#Removes existing weight numpy files to avoid confusion. \n",
    "def remove_weights():\n",
    "    if os.path.exists(\"data/input_self_attention.npy\"):\n",
    "        os.remove(\"data/input_self_attention.npy\")\n",
    "    if os.path.exists(\"data/cross_attention.npy\"):\n",
    "        os.remove(\"data/cross_attention.npy\")\n",
    "    if os.path.exists(\"data/output_self_attention.npy\"):\n",
    "        os.remove(\"data/output_self_attention.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_numpy_data():\n",
    "    if os.path.exists(\"data/cross_attention.npy\"):\n",
    "        input_data = np.load(\"data/cross_attention.npy\").reshape((6, 8, 100, 400))\n",
    "        np.save(\"data/cross_attention.npy\", input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_data(dataset, encode, fstyle):\n",
    "    input_list = list((dataset.vocab[i]) for i in np.array(encode[0]))\n",
    "    output_list = list((dataset.vocab[i]) for i in np.array(fstyle_words[0]))\n",
    "    val_1 = input_list.index('</s>') if '</s>' in input_list else 400\n",
    "    val_2 = output_list.index('</s>') if '</s>' in output_list else 100\n",
    "    \n",
    "    cross = np.load('data/cross_attention.npy')\n",
    "    cross = cross[:, :, :val_2, :val_1]\n",
    "    np.save('data/cross_attention.npy', cross)\n",
    "    \n",
    "    isa = np.load('data/input_self_attention.npy')\n",
    "    isa = isa[:, :, :val_1, :val_1]\n",
    "    np.save('data/input_self_attention.npy', isa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d0f940c6fe0449ab2b766b3bdd69177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News article:\n",
      "Ministry of Defence has withdrawn its attempt to strike out a whistleblowing claim brought by a doctor who raised concerns about alleged discrepancies in the dispensing of strong painkillers at an army base where he was working. Dr Stephen Frost, a civilian doctor who had worked with the military for 20 years, was dismissed three years ago by text and email while on a family holiday, and since then has sought to find out why and for redress from the MoD. At a hearing in Manchester, the MoD confirmed it had withdrawn its application to have Frost's claims struck out. John Hendy C, for Frost, told the tribunal the parties had reached a \"degree of agreement\". The hearing was adjourned so that discussions about a possible settlement could take place. No details of why the MoD had changed its approach were given. Frost, who was involved in the campaign for a full inquest on the weapons inspector David Kelly, who died at the height of the Iraq dossier scandal, described the last three years as a \"Kafkaesque nightmare\". He said: \"This has been a very difficult and sometimes lonely battle. The consequences for me and my family have been catastrophic. \"I have lost over three years of my life and I have been told that it may take some time for me to recover. I have learned of the importance to us all of whistleblowers and of laws being in place to protect adequately those whistleblowers.\" Frost's solicitor, Helen Clifford of MW Solicitors, said: \"Whistleblowers are modern-day heroes and the law urgently needs to be changed to afford them adequate protection. Dr Frost raised genuine concerns about potential criminality following a very serious dispensing error on a military camp and he believes that he was dismissed for doing so.\" In July 2013, Frost was engaged to work as a civilian doctor at Weeton barracks near Blackpool through\n",
      "---------------\n",
      "Gold summary: Dr Stephen Frost, who was dismissed by email in 2013, drew attention to an alleged dispensing discrepancy of prescription medication at an army base\n",
      "---------------\n",
      "Fast decode summary: Dr Stephen Frost, a civilian doctor who had worked with the military for 20 years, was dismissed three years ago by text and email while on family holiday\n",
      "---------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm.tqdm_notebook(range(1)):\n",
    "    remove_weights()\n",
    "    encode, decode, encoder_mask, decode_mask = dataset.build_batch(['input', 'output', 'input_mask', 'output_mask'], size=1, cut='evaluation', types=[tf.int32,tf.int32,tf.bool,tf.bool])\n",
    "\n",
    "    fstyle_decode_logits = model.test_decode(encode, output_length, encoder_mask=encoder_mask) # \n",
    "    fstyle_words = fstyle_decode_logits.numpy() + offset\n",
    "\n",
    "    decode += offset #Hack\n",
    "    encode += offset #Hack\n",
    "    \n",
    "    article_content = dataset.evaluate_sentence(encode.numpy())[0]\n",
    "    real_summary = dataset.evaluate_sentence(np.array(decode))[0]\n",
    "    \n",
    "    fstyle_summ = dataset.evaluate_sentence(fstyle_words)[0]\n",
    "    #tstyle_summ = dataset.evaluate_sentence(tstyle_words)[0]\n",
    "    \n",
    "    reshape_numpy_data()\n",
    "    trim_data(dataset, encode, fstyle_words)\n",
    "    #print (\"This sentence loss:\",test_loss.numpy())\n",
    "    print(\"News article:\")\n",
    "    print(article_content)\n",
    "    print(\"---------------\")\n",
    "    print(\"Gold summary:\",real_summary)\n",
    "    print(\"---------------\")\n",
    "    print(\"Fast decode summary:\",fstyle_summ)\n",
    "    print(\"---------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
