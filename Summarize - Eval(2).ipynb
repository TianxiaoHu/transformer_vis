{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rinokeras\n",
    "from rinokeras.models.transformer import Transformer\n",
    "import tensorflow.contrib.eager as tfe\n",
    "from Dataset import Dataset\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#import fastText\n",
    "import tqdm\n",
    "import os, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(\"nl_summaries_small_eval.0.4.json\")\n",
    "dataset.load()\n",
    "\n",
    "input_length = 400; output_length = 100; dim = 304\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "offset = 3 # Hack for now, due to beginning of word vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: No need to install unless you want to get Rouge / Meteor scores\n",
    "# Installation: https://github.com/Maluuba/nlg-eval\n",
    "# from nlgeval import NLGEval\n",
    "\n",
    "# n = NLGEval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vocab = len(dataset.vocab)\n",
    "print(n_vocab)\n",
    "model = Transformer(discrete=True, n_layers=3, n_symbols_in=n_vocab, d_model=dim, n_symbols_out=n_vocab, embedding_initializer=np.zeros((n_vocab, dim)), share_source_target_embedding=True)\n",
    "\n",
    "# Very hacky: do a forward run to force the model to be built, before loading the weights.\n",
    "encode, decode, mask, decode_mask = dataset.build_batch(['input', 'output', 'input_mask', 'output_mask'], size=64, cut='evaluation', types=[tf.int32,tf.int32,tf.bool,tf.bool])\n",
    "decoded_logits = model(encode, decode, encoder_mask=mask, decoder_mask=decode_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"summarize_adam_ckpt.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing loss in eager mode\n",
    "\n",
    "# encode, decode, mask, decode_mask = dataset.build_batch(['input', 'output', 'input_mask', 'output_mask'], size=64, cut='training', types=[tf.int32,tf.int32,tf.bool,tf.bool])\n",
    "# decoded_logits = model(encode, decode, encoder_mask=mask, decoder_mask=decode_mask)\n",
    "# train_loss = tf.losses.sparse_softmax_cross_entropy(decode, decoded_logits, tf.cast(decode_mask, tf.float32))\n",
    "# # train_loss = tf.contrib.seq2seq.sequence_loss(decoded_logits, decode, tf.cast(decode_mask, tf.float32))\n",
    "# print(\"Train loss:\",float(train_loss))\n",
    "\n",
    "encode, decode, mask, decode_mask = dataset.build_batch(['input', 'output', 'input_mask', 'output_mask'], size=64, cut='evaluation', types=[tf.int32,tf.int32,tf.bool,tf.bool])\n",
    "decoded_logits = model(encode, decode, encoder_mask=mask, decoder_mask=decode_mask)\n",
    "test_loss = tf.losses.sparse_softmax_cross_entropy(decode, decoded_logits, tf.cast(decode_mask, tf.float32))\n",
    "\n",
    "# test_loss = tf.contrib.seq2seq.sequence_loss(decoded_logits, decode, tf.cast(decode_mask, tf.float32))\n",
    "print(\"Eval loss:\",float(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm.tqdm_notebook(range(1)):\n",
    "    encode, decode, encoder_mask, decode_mask = dataset.build_batch(['input', 'output', 'input_mask', 'output_mask'], size=1, cut='evaluation', types=[tf.int32,tf.int32,tf.bool,tf.bool])\n",
    "\n",
    "    fstyle_decode_logits = model.test_decode(encode, output_length, encoder_mask=encoder_mask) # \n",
    "    #tstyle_decode_logits = model(encode, decode, encoder_mask=encoder_mask, decoder_mask=decode_mask) # Train style decoded output, cheating\n",
    "    #test_loss = tf.contrib.seq2seq.sequence_loss(tstyle_decode_logits, decode, tf.cast(decode_mask, tf.float32))\n",
    "    \n",
    "    #tstyle_words = np.argmax(tstyle_decode_logits, axis=2) + offset\n",
    "    fstyle_words = fstyle_decode_logits.numpy() + offset\n",
    "\n",
    "    decode += offset #Hack\n",
    "    encode += offset #Hack\n",
    "    \n",
    "    article_content = dataset.evaluate_sentence(encode.numpy())[0]\n",
    "    real_summary = dataset.evaluate_sentence(np.array(decode))[0]\n",
    "    \n",
    "    fstyle_summ = dataset.evaluate_sentence(fstyle_words)[0]\n",
    "    #tstyle_summ = dataset.evaluate_sentence(tstyle_words)[0]\n",
    "    \n",
    "    print (\"This sentence loss:\",test_loss.numpy())\n",
    "    print(\"News article:\")\n",
    "    print(article_content)\n",
    "    print(\"---------------\")\n",
    "    print(\"Gold summary:\",real_summary)\n",
    "    print(\"---------------\")\n",
    "    print(\"Fast decode summary:\",fstyle_summ)\n",
    "    print(\"---------------\")\n",
    "    #print(\"(Fake decoded summary: \"+tstyle_summ+\")\")\n",
    "    #print( \"==================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_self = np.load(\"input_self_attention.npy\").squeeze()\n",
    "output_self = np.load(\"output_self_attention.npy\").squeeze()\n",
    "cross = np.load(\"cross_attention.npy\").squeeze()\n",
    "\n",
    "#print(input_self.shape, output_self.shape, cross.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#fix, axes = plt.subplot(4,2)\n",
    "print('INPUT SELF ATTENTION')\n",
    "for i in range(8):\n",
    "    plt.title(\"Head \" + str(i))\n",
    "    plt.imshow(input_self[i], cmap = \"hot\")\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('OUTPUT SELF ATTENTION')\n",
    "for i in range(8):\n",
    "    plt.title(\"Head \" + str(i))\n",
    "    plt.imshow(output_self[i], cmap = \"hot\")\n",
    "    plt.show()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CROSS ATTENTION')\n",
    "for i in range(8):\n",
    "    plt.title(\"Head \" + str(i))\n",
    "    plt.imshow(cross[i], cmap = \"hot\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.load(\"weights.npy\")\n",
    "print(test.shape == (1, 8, 100, 400))\n",
    "test = np.squeeze(test)\n",
    "import matplotlib.pyplot as plt\n",
    "#fix, axes = plt.subplot(4,2)\n",
    "# for i in range(8):\n",
    "#     plt.imshow(test[i], cmap = \"hot\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation based on 6000 evaluation samples\n",
    "- 'Bleu_1': 0.25076293160378826\n",
    "- 'Bleu_2': 0.16896252164926842\n",
    "- 'Bleu_3': 0.13368250541763457\n",
    "- 'Bleu_4': 0.1138641951058073\n",
    "- 'METEOR': 0.13881139746244472\n",
    "- 'ROUGE_L': 0.21399892905364282\n",
    "- 'CIDEr': 0.725381810610675"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
